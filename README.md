<h1>RPC vs HTTP for MLOps</h1>

This repository contains the benchmark code and results for the HTTP vs RPC developed as part of the research project. The benchmarks aim to validate the performance advantages of using RPC framework over traditional HTTP-based approaches for machine learning model serving and deployment.

**Benchmark Scenarios**

The following benchmark scenarios are included in this repository:
- Model Serving Latency: Compares the response time of model inference requests between the RPC and HTTP based model serving implementations.
- Throughput and Scalability: Evaluates the maximum throughput and scalability of the RPC and HTTP based model serving under varying levels of concurrent requests.
